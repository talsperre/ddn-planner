{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/Users/shashanks./Downloads/Installations/ddn/\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ddn.pytorch.node import *\n",
    "from scipy.linalg import block_diag\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from bernstein import bernstein_coeff_order10_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CUDA Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_fin = 8.0\n",
    "num = 20\n",
    "\n",
    "tot_time = np.linspace(0.0, t_fin, num)\n",
    "tot_time_copy = tot_time.reshape(num, 1)\n",
    "P, Pdot, Pddot = bernstein_coeff_order10_new(10, tot_time_copy[0], tot_time_copy[-1], tot_time_copy)\n",
    "nvar = np.shape(P)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 11)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_eq_mat = np.vstack((P[0], Pdot[0], Pddot[0], P[-1], Pdot[-1], Pddot[-1]))\n",
    "A_eq_np = block_diag(A_eq_mat, A_eq_mat)\n",
    "Q_np = 10 * block_diag(np.dot(Pddot.T, Pddot), np.dot(Pddot.T, Pddot))\n",
    "q_np = np.zeros(2 * nvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QPNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QPNode(AbstractDeclarativeNode):\n",
    "    def __init__(self, Q_np, q_np, A_eq_np, rho=1.0, nvar=22, maxiter=1000):\n",
    "        super().__init__()\n",
    "        self.rho = rho\n",
    "        self.nvar = nvar\n",
    "        self.maxiter = maxiter\n",
    "        self.Q = torch.tensor(Q_np, dtype=torch.double).to(device)\n",
    "        self.q = torch.tensor(q_np, dtype=torch.double).to(device)\n",
    "        self.A = torch.tensor(A_eq_np, dtype=torch.double).to(device)\n",
    "    \n",
    "    def objective(self, b, lamda, y):\n",
    "        \"\"\"\n",
    "        b: (B x 12)\n",
    "        lamda: (B x 22)\n",
    "        y: (B x 22)\n",
    "        \"\"\"\n",
    "        lamda = lamda.transpose(0, 1)\n",
    "        y = y.transpose(0, 1)\n",
    "        cost_mat = self.rho * torch.matmul(self.A.T, self.A) + self.Q\n",
    "        lincost_mat = -self.rho * torch.matmul(b, self.A).T + self.q.view(-1, 1) - lamda\n",
    "        f = 0.5 * torch.diag(torch.matmul(y.T, torch.matmul(cost_mat, y))) + torch.diag(torch.matmul(lincost_mat.T, y))\n",
    "        return f\n",
    "    \n",
    "    def compute_augmented_lagrangian(self, b, lamda):\n",
    "        \"\"\"\n",
    "        b: (12,)\n",
    "        lamda: (22,)\n",
    "        \"\"\"\n",
    "        cost_mat = self.rho * torch.matmul(self.A.T, self.A) + self.Q\n",
    "        lincost_mat = -self.rho * torch.matmul(b, self.A).T + self.q - lamda\n",
    "        lincost_mat = lincost_mat.view(-1, 1)\n",
    "        sol, _ = torch.solve(lincost_mat, -cost_mat)\n",
    "        sol = sol.view(-1)\n",
    "        res = torch.matmul(self.A, sol) - b\n",
    "        return sol, res\n",
    "    \n",
    "    def optimize(self, b, lamda):\n",
    "        sol, res = self.compute_augmented_lagrangian(b, lamda)\n",
    "        for i in range(0, self.maxiter):\n",
    "            sol, res = self.compute_augmented_lagrangian(b, lamda)\n",
    "            lamda -= self.rho * torch.matmul(self.A.T, res)\n",
    "        return sol\n",
    "    \n",
    "    def solve(self, b, lamda):\n",
    "        batch_size, _ = b.size()\n",
    "        y = torch.zeros(batch_size, 22, dtype=torch.double).to(device)\n",
    "        for i in range(batch_size):\n",
    "            b_cur = b[i]\n",
    "            lamda_cur = lamda[i]\n",
    "            sol = self.optimize(b_cur, lamda_cur)\n",
    "            y[i, :] = sol\n",
    "        return y, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch Declarative Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QPFunction(torch.autograd.Function):\n",
    "    \"\"\"Generic declarative autograd function.\n",
    "    Defines the forward and backward functions. Saves all inputs and outputs,\n",
    "    which may be memory-inefficient for the specific problem.\n",
    "    \n",
    "    Assumptions:\n",
    "    * All inputs are PyTorch tensors\n",
    "    * All inputs have a single batch dimension (b, ...)\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, problem, *inputs):\n",
    "        output, solve_ctx = torch.no_grad()(problem.solve)(*inputs)\n",
    "        ctx.save_for_backward(output, *inputs)\n",
    "        ctx.problem = problem\n",
    "        ctx.solve_ctx = solve_ctx\n",
    "        return output.clone()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output, *inputs = ctx.saved_tensors\n",
    "        problem = ctx.problem\n",
    "        solve_ctx = ctx.solve_ctx\n",
    "        output.requires_grad = True\n",
    "        inputs = tuple(inputs)\n",
    "        grad_inputs = problem.gradient(*inputs, y=output, v=grad_output,\n",
    "            ctx=solve_ctx)\n",
    "        return (None, *grad_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch Declarative Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeclarativeLayer(torch.nn.Module):\n",
    "    \"\"\"Generic declarative layer.\n",
    "    \n",
    "    Assumptions:\n",
    "    * All inputs are PyTorch tensors\n",
    "    * All inputs have a single batch dimension (b, ...)\n",
    "    Usage:\n",
    "        problem = <derived class of *DeclarativeNode>\n",
    "        declarative_layer = DeclarativeLayer(problem)\n",
    "        y = declarative_layer(x1, x2, ...)\n",
    "    \"\"\"\n",
    "    def __init__(self, problem):\n",
    "        super(DeclarativeLayer, self).__init__()\n",
    "        self.problem = problem\n",
    "        \n",
    "    def forward(self, *inputs):\n",
    "        return QPFunction.apply(self.problem, *inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TrajNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajNet(nn.Module):\n",
    "    def __init__(self, opt_layer, P, input_size=16, hidden_size=64, output_size=12, nvar=11, t_obs=8):\n",
    "        super(TrajNet, self).__init__()\n",
    "        self.nvar = nvar\n",
    "        self.t_obs = t_obs\n",
    "        self.P = torch.tensor(P, dtype=torch.double).to(device)\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "        self.opt_layer = opt_layer\n",
    "        self.activation = nn.ReLU()\n",
    "        self.mask = torch.tensor([[1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]], dtype=torch.double).to(device)\n",
    "    \n",
    "    def forward(self, x, b):\n",
    "        batch_size, _ = x.size()\n",
    "        out = self.activation(self.linear1(x))\n",
    "        b_pred = self.linear2(out)\n",
    "        b_gen = self.mask * b + (1 - self.mask) * b_pred\n",
    "        \n",
    "        # Run optimization\n",
    "        lamda = torch.zeros(batch_size, 2 * self.nvar, dtype=torch.double).to(device)\n",
    "        sol = self.opt_layer(b_gen, lamda)\n",
    "        print(sol.size())\n",
    "        print(torch.matmul(self.P, sol[:, :self.nvar].transpose(0, 1)).size())\n",
    "        \n",
    "        # Compute final trajectory\n",
    "        x_pred = torch.matmul(self.P, sol[:, :self.nvar].transpose(0, 1))[self.t_obs:]\n",
    "        y_pred = torch.matmul(self.P, sol[:, self.nvar:].transpose(0, 1))[self.t_obs:]\n",
    "        print(x_pred.size(), y_pred.size())\n",
    "        \n",
    "        x_pred = x_pred.transpose(0, 1)\n",
    "        y_pred = y_pred.transpose(0, 1)\n",
    "        out = torch.cat([x_pred, y_pred], dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trajectory Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, root_dir, t_obs=8):\n",
    "        self.root_dir = root_dir\n",
    "        self.t_obs = t_obs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.root_dir))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_name = \"{}.npy\".format(idx)\n",
    "        file_path = os.path.join(self.root_dir, file_name)\n",
    "        \n",
    "        data = np.load(file_path, allow_pickle=True).item()\n",
    "        x_traj = data['x_traj']\n",
    "        y_traj = data['y_traj']\n",
    "        \n",
    "        x_inp = x_traj[:self.t_obs]\n",
    "        y_inp = y_traj[:self.t_obs]\n",
    "        x_fut = x_traj[self.t_obs:]\n",
    "        y_fut = y_traj[self.t_obs:]\n",
    "\n",
    "        traj_inp = np.dstack((x_inp, y_inp)).flatten()\n",
    "        traj_out = np.hstack((x_fut, y_fut)).flatten()\n",
    "        b_inp = np.array([data['x_init'], data['vx_init'], data['ax_init'], 0, 0, 0, data['y_init'], data['vy_init'], data['ay_init'], 0, 0, 0])\n",
    "        \n",
    "        return torch.tensor(traj_inp), torch.tensor(traj_out), torch.tensor(b_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrajectoryDataset(\"../datasets/data/\", 8)\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TrajectoryDataset(\"../datasets1/data/\", 8)\n",
    "test_loader = DataLoader(test_dataset, batch_size=20, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 16])\n"
     ]
    }
   ],
   "source": [
    "for batch_num, data in enumerate(train_loader):\n",
    "    traj_inp, traj_out, b_inp = data\n",
    "    print(traj_inp.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9509,  6.0606, -1.4452,  3.6275, -3.2600, 11.8367,  5.2798, 14.3161,\n",
       "        -4.7147,  5.9726,  1.6495, 15.0284, -3.4917, -4.2722,  0.8660, -0.8652,\n",
       "        -6.8108,  1.2075, -0.9170,  3.1887], dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traj_inp[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0155e+01,  1.6676e+00,  1.2164e-01,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  1.3217e+00,  5.4098e-01,  7.9870e-01,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-6.1901e+00,  3.9988e-01,  2.4077e-01,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  1.1493e+00,  1.8195e+00,  6.6076e-01,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-7.5099e+00,  2.4063e+00,  2.6080e-01,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00, -5.6933e+00,  1.5522e+00,  7.4712e-01,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 1.3217e+01,  2.3134e+00,  5.6554e-01,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00, -3.8643e+00,  2.4177e+00,  9.4448e-03,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 5.2593e+00,  1.1512e+00,  1.9182e-02,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00, -1.2664e+01,  2.2688e+00,  3.4699e-01,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 4.0670e+00,  1.2292e+00,  5.6723e-01,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  1.4091e+01,  1.9932e+00,  1.7728e-01,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-9.8370e+00,  2.8296e+00,  4.5078e-01,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  2.7849e+00,  9.1959e-01,  8.8434e-01,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-1.2245e+01,  1.6746e+00,  1.5298e-02,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  1.1430e+01,  2.1596e+00,  7.3869e-01,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-1.2625e+00,  1.2381e+00,  3.3006e-01,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00, -7.8611e+00,  1.2684e-01,  6.6648e-01,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 6.1951e-01,  2.4025e+00,  9.0835e-02,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  1.1729e+01,  3.5873e-01,  6.4734e-01,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 1.3858e+01,  2.1952e-01,  9.8668e-01,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00, -8.1340e+00,  2.9470e+00,  3.4660e-02,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 2.3686e+00,  2.1848e+00,  2.9765e-01,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  1.3048e+01,  2.4890e+00,  3.8306e-01,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 1.0125e+01,  9.2253e-01,  2.8608e-01,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00, -1.0355e+01,  4.9591e-01,  2.3034e-02,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-9.6312e+00,  2.8948e+00,  8.3978e-01,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00, -5.3565e+00,  1.2283e+00,  5.6894e-01,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-2.1183e+00,  2.8764e+00,  5.9694e-01,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00, -2.2899e+00,  2.3091e+00,  1.7003e-01,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 1.3698e+01,  1.0343e+00,  6.2820e-01,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00, -3.5107e+00,  2.4573e+00,  6.5650e-01,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [-1.3564e-01,  2.7915e+00,  4.8069e-01,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00, -7.2584e+00,  1.4340e+00,  8.4231e-01,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 2.4532e-01,  1.3393e+00,  5.0550e-01,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  5.8261e+00,  4.7854e-01,  4.4859e-01,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 6.9613e+00,  2.6278e+00,  5.4171e-01,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00, -8.6024e+00,  2.5913e+00,  2.9272e-01,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00],\n",
       "        [ 1.0702e+01,  1.0684e+00,  2.9536e-01,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00, -2.8397e+00,  1.1563e+00,  1.0005e-01,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00]], dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_inp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = QPNode(Q_np, q_np, A_eq_np)\n",
    "qp_layer = DeclarativeLayer(problem)\n",
    "\n",
    "model = TrajNet(qp_layer, P)\n",
    "model = model.double()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 22])\n",
      "torch.Size([20, 20])\n",
      "torch.Size([12, 20]) torch.Size([12, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-4.3574e+00, -3.6912e+00, -3.0554e+00, -2.4600e+00, -1.9157e+00,\n",
       "         -1.4313e+00, -1.0101e+00, -6.5229e-01, -3.5986e-01, -1.4431e-01,\n",
       "         -2.5318e-02, -3.3423e-04,  1.8945e+00,  1.7886e+00,  1.6641e+00,\n",
       "          1.5329e+00,  1.4023e+00,  1.2749e+00,  1.1506e+00,  1.0320e+00,\n",
       "          9.2797e-01,  8.5193e-01,  8.1397e-01,  8.0722e-01],\n",
       "        [-3.4292e+00, -2.9873e+00, -2.5483e+00, -2.1241e+00, -1.7260e+00,\n",
       "         -1.3625e+00, -1.0377e+00, -7.5411e-01, -5.1721e-01, -3.4088e-01,\n",
       "         -2.4385e-01, -2.2371e-01,  2.4916e+00,  2.1214e+00,  1.6959e+00,\n",
       "          1.2469e+00,  7.9796e-01,  3.6164e-01, -5.6453e-02, -4.4723e-01,\n",
       "         -7.8825e-01, -1.0427e+00, -1.1771e+00, -1.2031e+00],\n",
       "        [-2.2852e+00, -2.0018e+00, -1.7752e+00, -1.5942e+00, -1.4528e+00,\n",
       "         -1.3495e+00, -1.2828e+00, -1.2471e+00, -1.2310e+00, -1.2216e+00,\n",
       "         -1.2136e+00, -1.2108e+00, -1.1027e+00, -6.9019e-01, -3.1212e-01,\n",
       "          3.2602e-02,  3.4101e-01,  6.0819e-01,  8.3121e-01,  1.0118e+00,\n",
       "          1.1545e+00,  1.2605e+00,  1.3222e+00,  1.3360e+00],\n",
       "        [ 1.0093e+01,  8.6024e+00,  7.0237e+00,  5.4335e+00,  3.8946e+00,\n",
       "          2.4444e+00,  1.1011e+00, -1.1538e-01, -1.1561e+00, -1.9322e+00,\n",
       "         -2.3498e+00, -2.4335e+00,  1.8518e-01,  2.2661e-01,  2.0748e-01,\n",
       "          1.4686e-01,  5.8306e-02, -5.0970e-02, -1.7653e-01, -3.1063e-01,\n",
       "         -4.3762e-01, -5.3549e-01, -5.8656e-01, -5.9603e-01],\n",
       "        [ 3.3491e+00,  2.5454e+00,  1.6977e+00,  8.4535e-01,  2.1204e-02,\n",
       "         -7.5421e-01, -1.4706e+00, -2.1174e+00, -2.6701e+00, -3.0828e+00,\n",
       "         -3.3060e+00, -3.3510e+00, -5.2381e+00, -4.4408e+00, -3.6875e+00,\n",
       "         -2.9869e+00, -2.3503e+00, -1.7873e+00, -1.3023e+00, -8.9420e-01,\n",
       "         -5.6302e-01, -3.1890e-01, -1.8305e-01, -1.5418e-01],\n",
       "        [ 3.2687e+00,  2.6465e+00,  1.9797e+00,  1.3040e+00,  6.4721e-01,\n",
       "          2.5353e-02, -5.5438e-01, -1.0828e+00, -1.5365e+00, -1.8743e+00,\n",
       "         -2.0547e+00, -2.0904e+00,  9.8518e+00,  8.2528e+00,  6.5732e+00,\n",
       "          4.8894e+00,  3.2652e+00,  1.7400e+00,  3.3343e-01, -9.3465e-01,\n",
       "         -2.0167e+00, -2.8241e+00, -3.2605e+00, -3.3484e+00],\n",
       "        [-2.8887e+00, -2.3911e+00, -1.9576e+00, -1.5807e+00, -1.2585e+00,\n",
       "         -9.9279e-01, -7.8401e-01, -6.2686e-01, -5.1083e-01, -4.2729e-01,\n",
       "         -3.7783e-01, -3.6625e-01,  2.5288e+00,  2.1112e+00,  1.6594e+00,\n",
       "          1.2002e+00,  7.5356e-01,  3.2931e-01, -6.8787e-02, -4.3428e-01,\n",
       "         -7.4908e-01, -9.8220e-01, -1.1049e+00, -1.1287e+00],\n",
       "        [-5.9616e+00, -5.1880e+00, -4.4426e+00, -3.7396e+00, -3.0935e+00,\n",
       "         -2.5148e+00, -2.0079e+00, -1.5736e+00, -1.2164e+00, -9.5307e-01,\n",
       "         -8.0847e-01, -7.7837e-01,  8.2514e+00,  6.7918e+00,  5.2481e+00,\n",
       "          3.6952e+00,  2.1937e+00,  7.7984e-01, -5.2945e-01, -1.7149e+00,\n",
       "         -2.7289e+00, -3.4843e+00, -3.8902e+00, -3.9714e+00],\n",
       "        [-3.8201e-01, -6.3442e-01, -9.2400e-01, -1.2297e+00, -1.5354e+00,\n",
       "         -1.8324e+00, -2.1166e+00, -2.3818e+00, -2.6131e+00, -2.7861e+00,\n",
       "         -2.8778e+00, -2.8957e+00, -4.1847e+00, -3.4768e+00, -2.7614e+00,\n",
       "         -2.0609e+00, -1.3964e+00, -7.8362e-01, -2.3114e-01,  2.5555e-01,\n",
       "          6.6492e-01,  9.7112e-01,  1.1400e+00,  1.1751e+00],\n",
       "        [ 2.5735e+00,  2.1665e+00,  1.6908e+00,  1.1822e+00,  6.6851e-01,\n",
       "          1.6607e-01, -3.1643e-01, -7.6760e-01, -1.1623e+00, -1.4590e+00,\n",
       "         -1.6179e+00, -1.6493e+00,  6.8667e+00,  5.6665e+00,  4.4329e+00,\n",
       "          3.2157e+00,  2.0560e+00,  9.7864e-01, -5.2512e-03, -8.8465e-01,\n",
       "         -1.6298e+00, -2.1830e+00, -2.4809e+00, -2.5408e+00],\n",
       "        [ 7.9773e+00,  6.5877e+00,  5.1636e+00,  3.7617e+00,  2.4290e+00,\n",
       "          1.1929e+00,  6.5270e-02, -9.4177e-01, -1.7943e+00, -2.4262e+00,\n",
       "         -2.7658e+00, -2.8339e+00, -1.8225e+00, -1.4785e+00, -1.2030e+00,\n",
       "         -9.8348e-01, -8.1275e-01, -6.8819e-01, -6.0737e-01, -5.6329e-01,\n",
       "         -5.4290e-01, -5.3181e-01, -5.2312e-01, -5.2020e-01],\n",
       "        [ 3.4336e+00,  2.8991e+00,  2.2984e+00,  1.6708e+00,  1.0473e+00,\n",
       "          4.4548e-01, -1.2552e-01, -6.5404e-01, -1.1130e+00, -1.4568e+00,\n",
       "         -1.6406e+00, -1.6769e+00,  9.6433e+00,  8.0424e+00,  6.3476e+00,\n",
       "          4.6405e+00,  2.9880e+00,  1.4308e+00, -1.0844e-02, -1.3155e+00,\n",
       "         -2.4316e+00, -3.2644e+00, -3.7134e+00, -3.8035e+00],\n",
       "        [ 5.9369e+00,  4.7084e+00,  3.4330e+00,  2.1647e+00,  9.4882e-01,\n",
       "         -1.8656e-01, -1.2280e+00, -2.1624e+00, -2.9568e+00, -3.5484e+00,\n",
       "         -3.8680e+00, -3.9324e+00, -6.1028e+00, -5.3622e+00, -4.6205e+00,\n",
       "         -3.9008e+00, -3.2237e+00, -2.6030e+00, -2.0451e+00, -1.5546e+00,\n",
       "         -1.1433e+00, -8.3793e-01, -6.7149e-01, -6.3739e-01],\n",
       "        [-3.0028e+00, -2.6174e+00, -2.3012e+00, -2.0405e+00, -1.8290e+00,\n",
       "         -1.6666e+00, -1.5537e+00, -1.4838e+00, -1.4423e+00, -1.4132e+00,\n",
       "         -1.3918e+00, -1.3856e+00, -1.0903e+00, -6.2690e-01, -1.8813e-01,\n",
       "          2.2172e-01,  5.9589e-01,  9.2771e-01,  1.2135e+00,  1.4536e+00,\n",
       "          1.6486e+00,  1.7935e+00,  1.8753e+00,  1.8930e+00],\n",
       "        [ 2.1338e+00,  2.0296e+00,  1.8485e+00,  1.6212e+00,  1.3692e+00,\n",
       "          1.1031e+00,  8.2818e-01,  5.5490e-01,  3.0714e-01,  1.2035e-01,\n",
       "          2.3478e-02,  5.4197e-03,  1.1895e+00,  1.1371e+00,  1.0245e+00,\n",
       "          8.7401e-01,  7.0175e-01,  5.1615e-01,  3.2196e-01,  1.2731e-01,\n",
       "         -5.0360e-02, -1.8535e-01, -2.5610e-01, -2.6947e-01],\n",
       "        [ 8.9055e+00,  7.4904e+00,  6.0210e+00,  4.5604e+00,  3.1609e+00,\n",
       "          1.8542e+00,  6.5476e-01, -4.2221e-01, -1.3380e+00, -2.0191e+00,\n",
       "         -2.3861e+00, -2.4598e+00,  8.2660e-01,  8.8056e-01,  8.7091e-01,\n",
       "          8.1919e-01,  7.3942e-01,  6.3733e-01,  5.1566e-01,  3.8210e-01,\n",
       "          2.5460e-01,  1.5804e-01,  1.1006e-01,  1.0185e-01],\n",
       "        [ 2.0668e+00,  1.5587e+00,  9.6889e-01,  3.4157e-01, -2.8931e-01,\n",
       "         -9.0485e-01, -1.4956e+00, -2.0480e+00, -2.5308e+00, -2.8926e+00,\n",
       "         -3.0851e+00, -3.1228e+00, -2.4535e+00, -1.9600e+00, -1.4967e+00,\n",
       "         -1.0662e+00, -6.7476e-01, -3.2947e-01, -3.4597e-02,  2.1049e-01,\n",
       "          4.0826e-01,  5.5564e-01,  6.4001e-01,  6.5855e-01],\n",
       "        [ 1.4233e+00,  1.1904e+00,  9.1755e-01,  6.2663e-01,  3.3385e-01,\n",
       "          4.7486e-02, -2.2874e-01, -4.8847e-01, -7.1594e-01, -8.8570e-01,\n",
       "         -9.7497e-01, -9.9215e-01,  3.8272e+00,  3.2106e+00,  2.5690e+00,\n",
       "          1.9309e+00,  1.3194e+00,  7.4796e-01,  2.2258e-01, -2.5009e-01,\n",
       "         -6.5236e-01, -9.5110e-01, -1.1114e+00, -1.1434e+00],\n",
       "        [ 6.7327e+00,  5.7561e+00,  4.6932e+00,  3.6041e+00,  2.5369e+00,\n",
       "          1.5196e+00,  5.6581e-01, -3.0766e-01, -1.0606e+00, -1.6231e+00,\n",
       "         -1.9245e+00, -1.9844e+00, -2.3650e+00, -1.9295e+00, -1.5528e+00,\n",
       "         -1.2276e+00, -9.5164e-01, -7.2589e-01, -5.5024e-01, -4.1966e-01,\n",
       "         -3.2452e-01, -2.5661e-01, -2.1642e-01, -2.0697e-01],\n",
       "        [ 7.3711e+00,  6.2760e+00,  5.1327e+00,  3.9917e+00,  2.8948e+00,\n",
       "          1.8678e+00,  9.2307e-01,  7.3186e-02, -6.5071e-01, -1.1900e+00,\n",
       "         -1.4810e+00, -1.5396e+00, -5.1105e-01, -4.1251e-01, -3.4182e-01,\n",
       "         -2.9237e-01, -2.6012e-01, -2.4343e-01, -2.4123e-01, -2.5048e-01,\n",
       "         -2.6498e-01, -2.7714e-01, -2.8239e-01, -2.8292e-01]],\n",
       "       dtype=torch.float64, grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(traj_inp, b_inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 20]) torch.Size([12, 20])\n",
      "Epoch: 0, Batch: 0, Loss: 45.91413982231994\n",
      "torch.Size([12, 20]) torch.Size([12, 20])\n",
      "torch.Size([12, 20]) torch.Size([12, 20])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-680e220cead7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_train_loss = []\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = []\n",
    "    for batch_num, data in enumerate(train_loader):\n",
    "        traj_inp, traj_out, b_inp = data\n",
    "        traj_inp = traj_inp.to(device)\n",
    "        traj_out = traj_out.to(device)\n",
    "        b_inp = b_inp.to(device)\n",
    "\n",
    "        out = model(traj_inp, b_inp)\n",
    "        loss = criterion(out, traj_out)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        if batch_num % 10 == 0:\n",
    "            print(\"Epoch: {}, Batch: {}, Loss: {}\".format(epoch, batch_num, loss.item()))\n",
    "    \n",
    "    mean_loss = np.mean(train_loss)\n",
    "    epoch_train_loss.append(mean_loss)\n",
    "    print(\"Epoch: {}, Mean Loss: {}\".format(epoch, mean_loss))\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_inp[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_out[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_inp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_inp[0][::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_inp[0][1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_traj(i, traj_inp, traj_out, traj_pred):\n",
    "    traj_inp = traj_inp.numpy()\n",
    "    traj_out = traj_out.numpy()\n",
    "    traj_pred = traj_pred.numpy()\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    ax.scatter(traj_inp[::2], traj_inp[1::2], label='Inp traj')\n",
    "    ax.scatter(traj_out[:12], traj_out[12:], label='GT')\n",
    "    ax.scatter(traj_pred[:12], traj_pred[12:], label='Pred')\n",
    "    ax.legend()\n",
    "    ax.set_xlim([-20, 20])\n",
    "    ax.set_ylim([-20, 20])\n",
    "    plt.savefig('./results/{}.png'.format(i))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    cnt = 0\n",
    "    test_loss = []\n",
    "    for batch_num, data in enumerate(test_loader):\n",
    "        traj_inp, traj_out, b_inp = data\n",
    "        traj_inp = traj_inp.to(device)\n",
    "        traj_out = traj_out.to(device)\n",
    "        b_inp = b_inp.to(device)\n",
    "\n",
    "        out = model(traj_inp, b_inp)\n",
    "        loss = criterion(out, traj_out)\n",
    "        \n",
    "        test_loss.append(loss.item())\n",
    "        print(\"Batch: {}, Loss: {}\".format(batch_num, loss.item()))\n",
    "        \n",
    "        for i in range(traj_inp.size()[0]):\n",
    "            plot_traj(cnt, traj_inp[i], traj_out[i], out[i])\n",
    "            cnt += 1\n",
    "\n",
    "mean_loss = np.mean(test_loss)\n",
    "print(\"Epoch Mean Test Loss: {}\".format(mean_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = model(traj_inp, b_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out.size(), traj_out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_out[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean((test_out[14] - traj_out[14]) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion(test_out, traj_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
