{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/Users/shashanks./Downloads/Installations/ddn/\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.special\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ddn.pytorch.node import *\n",
    "from scipy.linalg import block_diag\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from bernstein import bernstein_coeff_order10_new\n",
    "\n",
    "torch.set_printoptions(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CUDA Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_obs = 0.3\n",
    "rho_eq = 10.0\n",
    "weight_smoothness = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 20\n",
    "t_fin = 8.0\n",
    "a_obs = 1.0\n",
    "b_obs = 1.0\n",
    "\n",
    "tot_time = np.linspace(0.0, t_fin, num)\n",
    "tot_time_copy = tot_time.reshape(num, 1)\n",
    "P, Pdot, Pddot = bernstein_coeff_order10_new(10, tot_time_copy[0], tot_time_copy[-1], tot_time_copy)\n",
    "nvar = np.shape(P)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_obs_temp = np.hstack((-2.0, -0.79, 3.0, 4.0))\n",
    "y_obs_temp = np.hstack((-2.0, 1.0, -0.80, 2.0))\n",
    "num_obs = np.shape(x_obs_temp)[0]\n",
    "\n",
    "x_obs = np.ones((num_obs, num)) * x_obs_temp[:, np.newaxis]\n",
    "y_obs = np.ones((num_obs, num)) * y_obs_temp[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_eq = np.vstack((P[0], Pdot[0], Pddot[0], P[-1], Pdot[-1], Pddot[-1]))\n",
    "A_obs = np.tile(P, (num_obs, 1))\n",
    "Q_smoothness = np.dot(Pddot.T, Pddot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxiter = 300\n",
    "eps = 10 ** (-8.0)\n",
    "num_tot = num_obs * num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 11]),\n",
       " torch.Size([6, 11]),\n",
       " torch.Size([80, 11]),\n",
       " torch.Size([11, 11]),\n",
       " torch.Size([4, 20]),\n",
       " torch.Size([4, 20]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_tensor = torch.tensor(P, dtype=torch.double)\n",
    "Pddot_tensor = torch.tensor(Pddot, dtype=torch.double)\n",
    "A_eq_tensor = torch.tensor(A_eq, dtype=torch.double)\n",
    "A_obs_tensor = torch.tensor(A_obs, dtype=torch.double)\n",
    "Q_smoothness_tensor = torch.tensor(Q_smoothness, dtype=torch.double)\n",
    "x_obs_tensor = torch.tensor(x_obs, dtype=torch.double)\n",
    "y_obs_tensor = torch.tensor(y_obs, dtype=torch.double)\n",
    "P_tensor.size(), A_eq_tensor.size(), A_obs_tensor.size(), Q_smoothness_tensor.size(), x_obs_tensor.size(), y_obs_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sol = torch.randn(10, 182, dtype=torch.double)\n",
    "# params = torch.randn(10, 12, dtype=torch.double)\n",
    "# lamda_x = torch.randn(10, 11, dtype=torch.double)\n",
    "# lamda_y = torch.randn(10, 11, dtype=torch.double)\n",
    "\n",
    "# sol = sol.transpose(0, 1)\n",
    "# params = params.transpose(0, 1)\n",
    "# lamda_x = lamda_x.transpose(0, 1)\n",
    "# lamda_y = lamda_y.transpose(0, 1)\n",
    "# sol.size(), params.size(), lamda_x.size(), lamda_y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params[:, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx_eq_tensor, by_eq_tensor = torch.split(params, 6, dim=0)\n",
    "\n",
    "c_x = sol[0:nvar]\n",
    "c_y = sol[nvar:2 * nvar]\n",
    "alpha_obs = sol[2 * nvar: 2 * nvar + num_tot]\n",
    "d_obs = sol[2 * nvar + num_tot:]\n",
    "\n",
    "cost_smoothness_x = 0.5 * weight_smoothness * torch.diag(torch.matmul(c_x.T, torch.matmul(Q_smoothness_tensor, c_x)))\n",
    "cost_smoothness_y = 0.5 * weight_smoothness * torch.diag(torch.matmul(c_y.T, torch.matmul(Q_smoothness_tensor, c_y)))\n",
    "\n",
    "temp_x_obs = d_obs * torch.cos(alpha_obs) * a_obs\n",
    "b_obs_x = x_obs_tensor.view(-1, 1) + temp_x_obs\n",
    "\n",
    "temp_y_obs = d_obs * torch.sin(alpha_obs) * b_obs\n",
    "b_obs_y = y_obs_tensor.view(-1, 1) + temp_y_obs\n",
    "\n",
    "cost_obs_x = 0.5 * rho_obs * (torch.sum((torch.matmul(A_obs_tensor, c_x) - b_obs_x) ** 2, axis=0))\n",
    "cost_obs_y = 0.5 * rho_obs * (torch.sum((torch.matmul(A_obs_tensor, c_y) - b_obs_y) ** 2, axis=0))\n",
    "cost_slack = rho_obs * torch.sum(F.relu(1 - d_obs), axis=0)\n",
    "\n",
    "cost_eq_x = 0.5 * rho_eq * torch.sum((torch.matmul(A_eq_tensor, c_x) - bx_eq_tensor) ** 2, axis=0)\n",
    "cost_eq_y = 0.5 * rho_eq * torch.sum((torch.matmul(A_eq_tensor, c_y) - by_eq_tensor) ** 2, axis=0)\n",
    "\n",
    "cost_x = cost_smoothness_x + cost_obs_x + cost_eq_x - torch.diag(torch.matmul(lamda_x.transpose(0, 1), c_x))\n",
    "cost_y = cost_smoothness_y + cost_obs_y + cost_eq_y - torch.diag(torch.matmul(lamda_y.transpose(0, 1), c_y))\n",
    "cost = cost_x + cost_y + eps * torch.sum(c_x ** 2, axis=0) + eps * torch.sum(c_y ** 2, axis=0) + eps * torch.sum(d_obs ** 2, axis=0) + eps * torch.sum(alpha_obs ** 2, axis=0) + cost_slack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_solution(b_tensor, lamda_x, lamda_y):\n",
    "    d_obs = torch.zeros(num_obs, num)\n",
    "    alpha_obs = torch.zeros(num_obs, num)\n",
    "    ones_tensor = torch.ones((num_obs, num), dtype=torch.double)\n",
    "    bx_eq_tensor, by_eq_tensor = torch.split(b_tensor, 6, dim=0)\n",
    "    cost_smoothness = weight_smoothness * torch.matmul(Pddot_tensor.T, Pddot_tensor)\n",
    "    cost = cost_smoothness + rho_obs * torch.matmul(A_obs_tensor.T, A_obs_tensor) + rho_eq * torch.matmul(A_eq_tensor.T, A_eq_tensor)\n",
    "    \n",
    "    for i in range(maxiter):\n",
    "        temp_x_obs = d_obs * torch.cos(alpha_obs) * a_obs\n",
    "        temp_y_obs = d_obs * torch.sin(alpha_obs) * b_obs\n",
    "        \n",
    "        b_obs_x = x_obs_tensor.view(num * num_obs) + temp_x_obs.view(num * num_obs)\n",
    "        b_obs_y = y_obs_tensor.view(num * num_obs) + temp_y_obs.view(num * num_obs)\n",
    "        \n",
    "        lincost_x = -lamda_x - rho_obs * torch.matmul(A_obs_tensor.T, b_obs_x) - rho_eq * torch.matmul(A_eq_tensor.T, bx_eq_tensor)\n",
    "        lincost_y = -lamda_y - rho_obs * torch.matmul(A_obs_tensor.T, b_obs_y) - rho_eq * torch.matmul(A_eq_tensor.T, by_eq_tensor)\n",
    "\n",
    "        lincost_x = lincost_x.view(-1, 1)\n",
    "        lincost_y = lincost_y.view(-1, 1)\n",
    "        \n",
    "        sol_x, _ = torch.solve(lincost_x, -cost)\n",
    "        sol_y, _ = torch.solve(lincost_y, -cost)\n",
    "\n",
    "        sol_x = sol_x.view(-1)\n",
    "        sol_y = sol_y.view(-1)\n",
    "        \n",
    "        x = torch.matmul(P_tensor, sol_x)\n",
    "        y = torch.matmul(P_tensor, sol_y)\n",
    "\n",
    "        wc_alpha = x - x_obs\n",
    "        ws_alpha = y - y_obs\n",
    "        alpha_obs = torch.atan2(ws_alpha * a_obs, wc_alpha * b_obs)\n",
    "        \n",
    "        c1_d = rho_obs * (a_obs ** 2 * torch.cos(alpha_obs) ** 2 + b_obs ** 2 * torch.sin(alpha_obs) ** 2)\n",
    "        c2_d = rho_obs * (a_obs * wc_alpha * torch.cos(alpha_obs) + b_obs * ws_alpha * torch.sin(alpha_obs))\n",
    "        d_temp = c2_d / c1_d\n",
    "        d_obs = torch.max(d_temp, ones_tensor)\n",
    "        \n",
    "        res_x_obs_vec = wc_alpha - a_obs * d_obs * torch.cos(alpha_obs)\n",
    "        res_y_obs_vec = ws_alpha - b_obs * d_obs * torch.sin(alpha_obs)\n",
    "        \n",
    "        res_eq_x_vec = torch.matmul(A_eq_tensor, sol_x) - bx_eq_tensor\n",
    "        res_eq_y_vec = torch.matmul(A_eq_tensor, sol_y) - by_eq_tensor\n",
    "        \n",
    "        lamda_x -= rho_obs * torch.matmul(A_obs_tensor.T, res_x_obs_vec.view(-1)) + rho_eq * torch.matmul(A_eq_tensor.T, res_eq_x_vec)\n",
    "        lamda_y -= rho_obs * torch.matmul(A_obs_tensor.T, res_y_obs_vec.view(-1)) + rho_eq * torch.matmul(A_eq_tensor.T, res_eq_y_vec)\n",
    "    \n",
    "    sol = torch.cat([sol_x, sol_y, alpha_obs.view(-1), d_obs.view(-1)])\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12]), torch.Size([11]), torch.Size([11]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_tensor = torch.tensor([-1.8047,  0.2048,  0.8956, -1.4917,  1.1513,  0.4862, -0.2575,  1.1148, \n",
    "                         0.8748, -0.0487, -1.0220,  0.6979], dtype=torch.double)\n",
    "\n",
    "lamda_x_test = torch.zeros(11)\n",
    "lamda_y_test = torch.zeros(11)\n",
    "b_tensor.size(), lamda_x_test.size(), lamda_y_test.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_obs = torch.ones(num_obs, num)\n",
    "alpha_obs = torch.zeros(num_obs, num)    \n",
    "ones_tensor = torch.ones((num_obs, num), dtype=torch.double)\n",
    "bx_eq_tensor, by_eq_tensor = torch.split(b_tensor, 6, dim=0)\n",
    "cost_smoothness = weight_smoothness * torch.matmul(Pddot_tensor.T, Pddot_tensor)\n",
    "cost = cost_smoothness + rho_obs * torch.matmul(A_obs_tensor.T, A_obs_tensor) + rho_eq * torch.matmul(A_eq_tensor.T, A_eq_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(maxiter):\n",
    "    temp_x_obs = d_obs * torch.cos(alpha_obs) * a_obs\n",
    "    temp_y_obs = d_obs * torch.sin(alpha_obs) * b_obs\n",
    "\n",
    "    b_obs_x = x_obs_tensor.view(num * num_obs) + temp_x_obs.view(num * num_obs)\n",
    "    b_obs_y = y_obs_tensor.view(num * num_obs) + temp_y_obs.view(num * num_obs)\n",
    "\n",
    "    lincost_x = -lamda_x_test - rho_obs * torch.matmul(A_obs_tensor.T, b_obs_x) - rho_eq * torch.matmul(A_eq_tensor.T, bx_eq_tensor)\n",
    "    lincost_y = -lamda_y_test - rho_obs * torch.matmul(A_obs_tensor.T, b_obs_y) - rho_eq * torch.matmul(A_eq_tensor.T, by_eq_tensor)\n",
    "\n",
    "    lincost_x = lincost_x.view(-1, 1)\n",
    "    lincost_y = lincost_y.view(-1, 1)\n",
    "\n",
    "    sol_x, _ = torch.solve(lincost_x, -cost)\n",
    "    sol_y, _ = torch.solve(lincost_y, -cost)\n",
    "\n",
    "    sol_x = sol_x.view(-1)\n",
    "    sol_y = sol_y.view(-1)\n",
    "\n",
    "    x = torch.matmul(P_tensor, sol_x)\n",
    "    y = torch.matmul(P_tensor, sol_y)\n",
    "\n",
    "    wc_alpha = x - x_obs\n",
    "    ws_alpha = y - y_obs\n",
    "    alpha_obs = torch.atan2(ws_alpha * a_obs, wc_alpha * b_obs)\n",
    "\n",
    "    c1_d = rho_obs * (a_obs ** 2 * torch.cos(alpha_obs) ** 2 + b_obs ** 2 * torch.sin(alpha_obs) ** 2)\n",
    "    c2_d = rho_obs * (a_obs * wc_alpha * torch.cos(alpha_obs) + b_obs * ws_alpha * torch.sin(alpha_obs))\n",
    "    d_temp = c2_d / c1_d\n",
    "    d_obs = torch.max(d_temp, ones_tensor)\n",
    "    # d_obs = F.relu(d_temp)\n",
    "\n",
    "    res_x_obs_vec = wc_alpha - a_obs * d_obs * torch.cos(alpha_obs)\n",
    "    res_y_obs_vec = ws_alpha - b_obs * d_obs * torch.sin(alpha_obs)\n",
    "\n",
    "    res_eq_x_vec = torch.matmul(A_eq_tensor, sol_x) - bx_eq_tensor\n",
    "    res_eq_y_vec = torch.matmul(A_eq_tensor, sol_y) - by_eq_tensor\n",
    "    \n",
    "    lamda_x_test -= rho_obs * torch.matmul(A_obs_tensor.T, res_x_obs_vec.view(-1)) + rho_eq * torch.matmul(A_eq_tensor.T, res_eq_x_vec)\n",
    "    lamda_y_test -= rho_obs * torch.matmul(A_obs_tensor.T, res_y_obs_vec.view(-1)) + rho_eq * torch.matmul(A_eq_tensor.T, res_eq_y_vec)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sol = torch.cat([sol_x, sol_y, alpha_obs.view(-1), d_obs.view(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = torch.tensor([  4.96621797, -19.05468109,  13.81199478,   0.0935155 ,\n",
    "         0.2375418 ,   0.25648372,   0.18693714,   0.06640255,\n",
    "        11.02021339, -15.01854218,   3.433404  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -5.96046448e-08,\n",
       "         1.04308128e-07,  1.19209290e-07, -8.94069672e-08,  0.00000000e+00,\n",
       "         9.53674316e-07,  0.00000000e+00,  2.38418579e-07])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lamda_y_test - tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable Size and PyTorch Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_obs = torch.zeros(num_obs, num)\n",
    "alpha_obs = torch.zeros(num_obs, num)\n",
    "lamda_x = torch.zeros(nvar)\n",
    "lamda_y = torch.zeros(nvar)\n",
    "res_obs = torch.ones(maxiter)\n",
    "res_eq = torch.ones(maxiter)\n",
    "d_min = torch.ones(maxiter)\n",
    "alpha_obs.size(), alpha_obs.size(), lamda_x.size(), lamda_y.size(), res_obs.size(), res_eq.size(), d_min.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_smoothness = weight_smoothness * torch.matmul(Pddot_tensor.T, Pddot_tensor)\n",
    "cost = cost_smoothness + rho_obs * torch.matmul(A_obs_tensor.T, A_obs_tensor) + rho_eq * torch.matmul(A_eq_tensor.T, A_eq_tensor)\n",
    "cost_smoothness.size(), cost.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_x_obs = d_obs * torch.cos(alpha_obs) * a_obs\n",
    "temp_y_obs = d_obs * torch.sin(alpha_obs) * b_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_obs_x = x_obs_tensor.view(num * num_obs) + temp_x_obs.view(num * num_obs)\n",
    "b_obs_y = y_obs_tensor.view(num * num_obs) + temp_y_obs.view(num * num_obs)\n",
    "b_obs_x.size(), b_obs_y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx_eq_tensor1 = params[:6, 0]\n",
    "by_eq_tensor1 = params[6:, 0]\n",
    "bx_eq_tensor1.size(), by_eq_tensor1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul(A_obs_tensor.T, b_obs_x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_eq_tensor.size(), bx_eq_tensor1.size()\n",
    "# torch.matmul(A_eq_tensor.T, bx_eq_tensor1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lincost_x = -lamda_x - rho_obs * torch.matmul(A_obs_tensor.T, b_obs_x) - rho_eq * torch.matmul(A_eq_tensor.T, bx_eq_tensor1)\n",
    "lincost_y = -lamda_y - rho_obs * torch.matmul(A_obs_tensor.T, b_obs_y) - rho_eq * torch.matmul(A_eq_tensor.T, by_eq_tensor1)\n",
    "\n",
    "lincost_x = lincost_x.view(-1, 1)\n",
    "lincost_y = lincost_y.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_x, _ = torch.solve(lincost_x, -cost)\n",
    "sol_y, _ = torch.solve(lincost_y, -cost)\n",
    "\n",
    "sol_x = sol_x.view(-1)\n",
    "sol_y = sol_y.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.matmul(P_tensor, sol_x)\n",
    "y = torch.matmul(P_tensor, sol_y)\n",
    "\n",
    "wc_alpha = x - x_obs\n",
    "ws_alpha = y - y_obs\n",
    "alpha_obs = torch.atan2(ws_alpha * a_obs, wc_alpha * b_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_d = rho_obs * (a_obs ** 2 * torch.cos(alpha_obs) ** 2 + b_obs ** 2 * torch.sin(alpha_obs) ** 2)\n",
    "c2_d = rho_obs * (a_obs * wc_alpha * torch.cos(alpha_obs) + b_obs * ws_alpha * torch.sin(alpha_obs))\n",
    "d_temp = c2_d / c1_d\n",
    "d_obs = F.relu(d_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_x_obs_vec = wc_alpha - a_obs * d_obs * torch.cos(alpha_obs)\n",
    "res_y_obs_vec = ws_alpha - b_obs * d_obs * torch.sin(alpha_obs)\n",
    "res_x_obs_vec.size(), res_y_obs_vec.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_eq_x_vec = torch.matmul(A_eq_tensor, sol_x) - bx_eq_tensor1\n",
    "res_eq_y_vec = torch.matmul(A_eq_tensor, sol_y) - by_eq_tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamda_x -= rho_obs * torch.matmul(A_obs_tensor.T, res_x_obs_vec.view(-1)) + rho_eq * torch.matmul(A_eq_tensor.T, res_eq_x_vec)\n",
    "lamda_y -= rho_obs * torch.matmul(A_obs_tensor.T, res_y_obs_vec.view(-1)) + rho_eq * torch.matmul(A_eq_tensor.T, res_eq_y_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
